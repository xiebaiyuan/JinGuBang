#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Android SOæ–‡ä»¶åˆ†æå·¥å…·
ç”¨äºå…¨é¢åˆ†æAndroid SOåº“æ–‡ä»¶çš„å„é¡¹ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
- æ–‡ä»¶åŸºæœ¬ä¿¡æ¯ï¼ˆå¤§å°ã€å“ˆå¸Œå€¼ç­‰ï¼‰
- SOåº“æ¶æ„ä¿¡æ¯
- å¯¼å‡ºç¬¦å·è¡¨
- ä¾èµ–çš„å…¶ä»–åº“
- å¯¹é½æ–¹å¼ï¼ˆæ”¯æŒ16KBå¯¹é½æ£€æµ‹ï¼‰
- ELFå¤´ä¿¡æ¯
- å“ˆå¸Œæ ·å¼ï¼ˆGNU Hash/SysV Hashï¼‰
- é‡å®šä½è¡¨å‹ç¼©ï¼ˆAndroid Pack Relocationsï¼‰
- NDKç‰ˆæœ¬åˆ†æï¼ˆé€šè¿‡Clangç‰ˆæœ¬æ¨æ–­ï¼‰
"""

import os
import sys
import hashlib
import subprocess
import argparse
import json
import textwrap
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Union
import re
import platform

def colorize(text, color_code):
    """ä¸ºç»ˆç«¯è¾“å‡ºæ·»åŠ é¢œè‰²"""
    if sys.stdout.isatty():  # åªåœ¨çœŸå®ç»ˆç«¯ä¸­åº”ç”¨é¢œè‰²
        return f"\033[{color_code}m{text}\033[0m"
    return text

def print_header(text):
    """æ‰“å°å¸¦é¢œè‰²çš„æ ‡é¢˜"""
    header = f" {text} "
    terminal_width = os.get_terminal_size().columns if sys.stdout.isatty() else 80
    padding = "=" * ((terminal_width - len(header)) // 2)
    print(colorize(f"\n{padding}{header}{padding}", "1;36"))

def print_subheader(text):
    """æ‰“å°å¸¦é¢œè‰²çš„å­æ ‡é¢˜"""
    print(colorize(f"\nâ–¶ {text}", "1;33"))

def print_info(label, value, color="0;32"):
    """æ‰“å°å¸¦é¢œè‰²çš„ä¿¡æ¯è¡Œ"""
    print(f"  {colorize(label, '1;37')}: {colorize(value, color)}")

def print_warning(text):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print(colorize(f"  âš ï¸  {text}", "1;33"))

def print_error(text):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(colorize(f"  âŒ {text}", "1;31"))

def print_success(text):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(colorize(f"  âœ… {text}", "1;32"))

def print_table(headers, rows, column_widths=None):
    """æ‰“å°æ ¼å¼åŒ–è¡¨æ ¼"""
    if not rows:
        return
        
    if not column_widths:
        # è®¡ç®—æ¯åˆ—çš„æœ€å¤§å®½åº¦
        column_widths = [len(h) for h in headers]
        for row in rows:
            for i, cell in enumerate(row):
                cell_str = str(cell)
                if i < len(column_widths):
                    column_widths[i] = max(column_widths[i], len(cell_str))
    
    # æ‰“å°è¡¨å¤´
    header_line = "  "
    for i, header in enumerate(headers):
        header_line += colorize(header.ljust(column_widths[i] + 2), "1;37")
    print(header_line)
    
    # æ‰“å°åˆ†éš”çº¿
    separator = "  " + "â”€" * (sum(column_widths) + len(headers) * 2)
    print(colorize(separator, "0;37"))
    
    # æ‰“å°æ•°æ®è¡Œ
    for row in rows:
        row_line = "  "
        for i, cell in enumerate(row):
            cell_str = str(cell)
            if i < len(column_widths):
                row_line += cell_str.ljust(column_widths[i] + 2)
        print(row_line)

def print_symbol_details(symbols, max_symbols=20, filter_type=None, show_all=False):
    """æ‰“å°è¯¦ç»†çš„ç¬¦å·ä¿¡æ¯"""
    # ç¬¦å·ç±»å‹è¯´æ˜
    type_descriptions = {
        'T': 'å¯¼å‡ºå‡½æ•° (text)',
        'W': 'å¼±ç¬¦å·',
        'R': 'åªè¯»æ•°æ® (read-only data)',
        'D': 'åˆå§‹åŒ–æ•°æ® (data)',
        'B': 'æœªåˆå§‹åŒ–æ•°æ® (BSS)',
        'U': 'æœªå®šä¹‰ç¬¦å· (ä¾èµ–å¤–éƒ¨)',
        'V': 'å¼±å¯¹è±¡',
        'w': 'å¼±æœªå®šä¹‰ç¬¦å·'
    }
    
    filtered_symbols = symbols
    if filter_type:
        filtered_symbols = [s for s in symbols if s['type'] == filter_type]
    
    headers = ["ç±»å‹", "åœ°å€", "ç¬¦å·å"]
    rows = []
    
    display_count = len(filtered_symbols) if show_all else min(max_symbols, len(filtered_symbols))
    
    for i in range(display_count):
        symbol = filtered_symbols[i]
        sym_type = symbol['type']
        sym_addr = symbol.get('address', 'N/A')
        rows.append([sym_type, sym_addr, symbol['name']])
    
    if rows:
        print_table(headers, rows)
        if not show_all and len(filtered_symbols) > max_symbols:
            print(f"\n  ... å…±æœ‰ {len(filtered_symbols)} ä¸ªç¬¦å·ï¼Œåªæ˜¾ç¤ºå‰ {max_symbols} ä¸ªã€‚ä½¿ç”¨ --show-all-symbols é€‰é¡¹æŸ¥çœ‹å…¨éƒ¨ã€‚")
    else:
        print_warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦å·")

def get_file_basic_info(file_path):
    """è·å–æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯ï¼šå¤§å°ã€æ—¶é—´æˆ³ã€MD5ã€SHA1ã€SHA256ç­‰"""
    file_stats = os.stat(file_path)
    file_size = file_stats.st_size
    modified_time = datetime.fromtimestamp(file_stats.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
    
    # è®¡ç®—å„ç§å“ˆå¸Œå€¼
    md5_hash = hashlib.md5()
    sha1_hash = hashlib.sha1()
    sha256_hash = hashlib.sha256()
    
    with open(file_path, 'rb') as f:
        # è¯»å–æ–‡ä»¶å†…å®¹å¹¶æ›´æ–°å“ˆå¸Œå¯¹è±¡
        chunk = f.read(8192)
        while chunk:
            md5_hash.update(chunk)
            sha1_hash.update(chunk)
            sha256_hash.update(chunk)
            chunk = f.read(8192)
    
    return {
        'file_name': os.path.basename(file_path),
        'file_path': file_path,
        'file_size': {
            'bytes': file_size,
            'human_readable': format_size(file_size)
        },
        'modified_time': modified_time,
        'md5': md5_hash.hexdigest(),
        'sha1': sha1_hash.hexdigest(),
        'sha256': sha256_hash.hexdigest()
    }

def format_size(size_bytes):
    """å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºäººç±»å¯è¯»æ ¼å¼"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024 or unit == 'GB':
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024

def get_so_architecture(file_path):
    """è·å–SOåº“çš„æ¶æ„ä¿¡æ¯"""
    try:
        result = subprocess.run(['file', file_path], capture_output=True, text=True, check=True)
        file_info = result.stdout
        
        arch_info = {
            'file_info': file_info.strip(),
            'architecture': 'unknown'
        }
        
        # åˆ†ææ¶æ„ç±»å‹
        if 'ARM aarch64' in file_info:
            arch_info['architecture'] = 'arm64-v8a'
        elif 'ARM,' in file_info:
            arch_info['architecture'] = 'armeabi-v7a'
        elif 'Intel 80386' in file_info:
            arch_info['architecture'] = 'x86'
        elif 'x86-64' in file_info:
            arch_info['architecture'] = 'x86_64'
        
        return arch_info
    except subprocess.CalledProcessError as e:
        return {'error': f"Error getting architecture info: {e}"}

def get_symbol_type_description(symbol_type):
    """è·å–ç¬¦å·ç±»å‹çš„æè¿°"""
    descriptions = {
        'T': 'å¯¼å‡ºå‡½æ•° (text section)',
        'W': 'å¼±ç¬¦å· (weak symbol)',
        'R': 'åªè¯»æ•°æ® (read-only data)',
        'D': 'åˆå§‹åŒ–æ•°æ® (initialized data)',
        'B': 'æœªåˆå§‹åŒ–æ•°æ® (uninitialized data)',
        'U': 'æœªå®šä¹‰ç¬¦å· (ä¾èµ–å¤–éƒ¨)',
        'V': 'å¼±å¯¹è±¡ (weak object)',
        'w': 'å¼±æœªå®šä¹‰ç¬¦å·'
    }
    return descriptions.get(symbol_type, 'æœªçŸ¥ç¬¦å·ç±»å‹')

def get_exported_symbols(file_path):
    """è·å–SOåº“å¯¼å‡ºçš„ç¬¦å·è¡¨"""
    ndk_root = os.environ.get('NDK_ROOT')
    if not ndk_root:
        return {'error': 'NDK_ROOTç¯å¢ƒå˜é‡æœªè®¾ç½®'}
    
    try:
        # è·å–æ–‡ä»¶æ¶æ„ä¿¡æ¯
        arch_info = get_so_architecture(file_path)
        arch = arch_info.get('architecture', 'unknown')
        
        # é€‰æ‹©é€‚å½“çš„nmå·¥å…·
        nm_path = None
        if arch == 'arm64-v8a':
            nm_path = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-nm')
        elif arch == 'armeabi-v7a':
            nm_path = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-nm')
        elif arch == 'x86':
            nm_path = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-nm')
        elif arch == 'x86_64':
            nm_path = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-nm')
        
        if not nm_path or not os.path.exists(nm_path):
            # å¦‚æœæ‰¾ä¸åˆ°ç‰¹å®šçš„nmå·¥å…·ï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤çš„nm
            nm_path = 'nm'
        
        # è·å–æ‰€æœ‰ç¬¦å·
        result = subprocess.run([nm_path, '-D', '--demangle', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error getting symbols: {result.stderr}'}
        
        # è§£æç¬¦å·è¡¨è¾“å‡º
        all_symbols = []
        for line in result.stdout.splitlines():
            if line.strip():
                parts = line.split()
                if len(parts) >= 3:  # åœ°å€ã€ç±»å‹ã€ç¬¦å·å
                    addr = parts[0]
                    symbol_type = parts[1]
                    symbol_name = ' '.join(parts[2:])  # æ”¯æŒæœ‰ç©ºæ ¼çš„ç¬¦å·å
                    all_symbols.append({
                        'address': addr,
                        'type': symbol_type, 
                        'name': symbol_name
                    })
                elif len(parts) == 2:  # ç±»å‹ã€ç¬¦å·åï¼ˆæ— åœ°å€ï¼‰
                    symbol_type = parts[0]
                    symbol_name = parts[1]
                    all_symbols.append({
                        'address': 'N/A',
                        'type': symbol_type, 
                        'name': symbol_name
                    })
        
        # è·å–ä»…å®šä¹‰çš„å¯¼å‡ºç¬¦å·ï¼ˆå³æš´éœ²çš„ç¬¦å·ï¼‰
        defined_result = subprocess.run([nm_path, '-D', '--defined-only', '--demangle', file_path], 
                                        capture_output=True, text=True)
        
        exported_symbols = []
        if defined_result.returncode == 0:
            for line in defined_result.stdout.splitlines():
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 3:  # åœ°å€ã€ç±»å‹ã€ç¬¦å·å
                        addr = parts[0]
                        symbol_type = parts[1]
                        symbol_name = ' '.join(parts[2:])  # æ”¯æŒæœ‰ç©ºæ ¼çš„ç¬¦å·å
                        exported_symbols.append({
                            'address': addr,
                            'type': symbol_type, 
                            'name': symbol_name
                        })
                    elif len(parts) == 2:  # ç±»å‹ã€ç¬¦å·åï¼ˆæ— åœ°å€ï¼‰
                        symbol_type = parts[0]
                        symbol_name = parts[1]
                        exported_symbols.append({
                            'address': 'N/A',
                            'type': symbol_type, 
                            'name': symbol_name
                        })
        
        # æŒ‰ç±»å‹æ’åºç¬¦å·
        all_symbols.sort(key=lambda x: x['type'])
        exported_symbols.sort(key=lambda x: x['type'])
        
        # ç»Ÿè®¡æ‰€æœ‰ç¬¦å·ç±»å‹
        all_symbol_stats = {}
        for symbol in all_symbols:
            sym_type = symbol['type']
            if sym_type in all_symbol_stats:
                all_symbol_stats[sym_type] += 1
            else:
                all_symbol_stats[sym_type] = 1
        
        # ç»Ÿè®¡å¯¼å‡ºç¬¦å·ç±»å‹
        exported_symbol_stats = {}
        for symbol in exported_symbols:
            sym_type = symbol['type']
            if sym_type in exported_symbol_stats:
                exported_symbol_stats[sym_type] += 1
            else:
                exported_symbol_stats[sym_type] = 1
        
        # å°†ç»Ÿè®¡æ•°æ®è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œä¾¿äºæ’åº
        all_symbol_stats_list = [{'type': t, 'count': c, 'description': get_symbol_type_description(t)} 
                                for t, c in all_symbol_stats.items()]
        all_symbol_stats_list.sort(key=lambda x: x['count'], reverse=True)
        
        exported_symbol_stats_list = [{'type': t, 'count': c, 'description': get_symbol_type_description(t)} 
                                     for t, c in exported_symbol_stats.items()]
        exported_symbol_stats_list.sort(key=lambda x: x['count'], reverse=True)
        
        return {
            'total_symbols': len(all_symbols),
            'total_exported_symbols': len(exported_symbols),
            'symbol_stats': all_symbol_stats,
            'symbol_stats_list': all_symbol_stats_list,
            'exported_symbol_stats': exported_symbol_stats,
            'exported_symbol_stats_list': exported_symbol_stats_list,
            'symbols': all_symbols,
            'exported_symbols': exported_symbols
        }
    except Exception as e:
        return {'error': f'Error analyzing symbols: {str(e)}'}

def get_dependencies(file_path):
    """è·å–SOåº“çš„ä¾èµ–ä¿¡æ¯"""
    try:
        # ä½¿ç”¨readelfå·¥å…·è·å–ä¾èµ–åº“ä¿¡æ¯
        ndk_root = os.environ.get('NDK_ROOT')
        if not ndk_root:
            readelf_cmd = 'readelf'  # ä½¿ç”¨ç³»ç»Ÿè‡ªå¸¦çš„readelf
        else:
            arch_info = get_so_architecture(file_path)
            arch = arch_info.get('architecture', 'unknown')
            readelf_cmd = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-readelf')
            if not os.path.exists(readelf_cmd):
                readelf_cmd = 'readelf'  # å¤‡é€‰æ–¹æ¡ˆ
        
        result = subprocess.run([readelf_cmd, '-d', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error getting dependencies: {result.stderr}'}
        
        # è§£æä¾èµ–åº“
        dependencies = []
        for line in result.stdout.splitlines():
            if 'NEEDED' in line and 'Shared library' in line:
                # æå–æ‹¬å·ä¸­çš„åº“å
                lib_start = line.find('[') + 1
                lib_end = line.find(']')
                if lib_start > 0 and lib_end > lib_start:
                    lib_name = line[lib_start:lib_end]
                    dependencies.append(lib_name)
        
        return {
            'total_dependencies': len(dependencies),
            'dependencies': dependencies
        }
    except Exception as e:
        return {'error': f'Error analyzing dependencies: {str(e)}'}

def check_alignment(file_path):
    """æ£€æŸ¥SOæ–‡ä»¶çš„å¯¹é½æ–¹å¼ï¼ŒåŒ…æ‹¬ZIPå¯¹é½å’ŒLOADæ®µå¯¹é½"""
    try:
        # è·å–æ–‡ä»¶å¤§å°ç”¨äºZIPå¯¹é½æ£€æµ‹
        file_stats = os.stat(file_path)
        file_size = file_stats.st_size
        
        alignment_info = {
            'file_size': file_size,
            'zip_alignment': {},
            'load_alignment': {}
        }
        
        # æ£€æµ‹ZIPå¯¹é½ï¼ˆAndroid APKä¸­çš„SOæ–‡ä»¶å¯¹é½ï¼‰
        # ZIPå¯¹é½æ˜¯ä¸ºäº†ä¼˜åŒ–APKä¸­çš„SOæ–‡ä»¶åœ¨å†…å­˜ä¸­çš„åŠ è½½å’Œæ˜ å°„
        # å¸¸è§çš„å¯¹é½å¤§å°ï¼š16KB (0x4000) æˆ– 64KB (0x10000)
        zip_alignments = [16384, 65536]  # 16KB, 64KB
        zip_alignment_found = False
        for align in zip_alignments:
            if file_size % align == 0:
                alignment_info['zip_alignment'] = {
                    'alignment': f'0x{align:x}',
                    'alignment_bytes': align,
                    'alignment_human': f'{align//1024}KB',
                    'is_aligned': True,
                    'purpose': 'APKå‹ç¼©ä¼˜åŒ–',
                    'benefit': 'å‡å°‘å†…å­˜æ˜ å°„å¼€é”€'
                }
                zip_alignment_found = True
                break
        
        if not zip_alignment_found:
            # æ‰¾åˆ°æœ€æ¥è¿‘çš„å¯¹é½
            min_remainder = float('inf')
            best_align = 0
            for align in zip_alignments:
                remainder = file_size % align
                if remainder < min_remainder:
                    min_remainder = remainder
                    best_align = align
            alignment_info['zip_alignment'] = {
                'alignment': f'0x{best_align:x}',
                'alignment_bytes': best_align,
                'alignment_human': f'{best_align//1024}KB',
                'is_aligned': False,
                'remainder': min_remainder,
                'purpose': 'APKå‹ç¼©ä¼˜åŒ–',
                'benefit': 'å‡å°‘å†…å­˜æ˜ å°„å¼€é”€',
                'recommendation': f'å»ºè®®å¡«å…… {min_remainder} å­—èŠ‚ä»¥è¾¾åˆ° {best_align//1024}KB å¯¹é½'
            }
        
        # ä½¿ç”¨readelfè·å–æ®µä¿¡æ¯
        readelf_cmd = 'readelf'  # å…ˆå°è¯•ç³»ç»Ÿè‡ªå¸¦çš„readelf
        objdump_cmd = 'objdump'
        
        # å°è¯•ä½¿ç”¨NDKä¸­çš„å·¥å…·
        ndk_root = os.environ.get('NDK_ROOT')
        if ndk_root:
            ndk_readelf = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-readelf')
            ndk_objdump = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-objdump')
            if os.path.exists(ndk_readelf):
                readelf_cmd = ndk_readelf
            if os.path.exists(ndk_objdump):
                objdump_cmd = ndk_objdump
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨objdump -på‘½ä»¤è·å–ç¨‹åºå¤´ä¿¡æ¯ï¼ˆæ›´å‡†ç¡®çš„å¯¹é½ä¿¡æ¯ï¼‰
        try:
            result = subprocess.run([objdump_cmd, '-p', file_path], capture_output=True, text=True)
            
            if result.returncode == 0:
                alignment_info['load_alignment']['raw_info'] = ''
                found_align = False
                max_align = 0
                
                # è§£æLOADæ®µçš„å¯¹é½ä¿¡æ¯
                for line in result.stdout.splitlines():
                    line = line.strip()
                    # è®°å½•åŸå§‹ä¿¡æ¯
                    if 'LOAD' in line:
                        alignment_info['load_alignment']['raw_info'] += line + '\n'
                        
                        # å°è¯•è§£æå¯¹é½å€¼ï¼Œæ ¼å¼å¯èƒ½æ˜¯ "align 2**14" æˆ–å…¶ä»–æ ¼å¼
                        align_match = re.search(r'align\s+2\*\*(\d+)', line)
                        if align_match:
                            align_power = int(align_match.group(1))
                            align_value = 2 ** align_power
                            # ä¿å­˜æœ€å¤§çš„å¯¹é½å€¼
                            if align_value > max_align:
                                max_align = align_value
                                alignment_info['load_alignment']['alignment'] = f'0x{align_value:x}'
                                alignment_info['load_alignment']['alignment_bytes'] = align_value
                                alignment_info['load_alignment']['alignment_power'] = align_power
                                found_align = True
                
                if found_align:
                    # æ·»åŠ å¯¹é½è¯„ä¼°ä¿¡æ¯
                    align_value = alignment_info['load_alignment'].get('alignment_bytes', 0)
                    if align_value >= 65536:  # 64Kå¯¹é½
                        alignment_info['load_alignment']['assessment'] = 'Excellent (64K alignment)'
                    elif align_value >= 16384:  # 16Kå¯¹é½
                        alignment_info['load_alignment']['assessment'] = 'Very Good (16K alignment)'
                    elif align_value >= 4096:  # 4Kå¯¹é½
                        alignment_info['load_alignment']['assessment'] = 'Good (4K alignment)'
                    elif align_value >= 1024:  # 1Kå¯¹é½
                        alignment_info['load_alignment']['assessment'] = 'Acceptable (1K alignment)'
                    else:
                        alignment_info['load_alignment']['assessment'] = f'Sub-optimal ({align_value} bytes alignment)'
                    
                    return alignment_info
        except Exception as e:
            # å¦‚æœobjdumpå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å°è¯•readelf
            pass
        
        # å¦‚æœobjdumpæ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨readelf -lå‘½ä»¤
        result = subprocess.run([readelf_cmd, '-l', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            # å¦‚æœreadelfä¹Ÿå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨fileå‘½ä»¤ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            file_result = subprocess.run(['file', file_path], capture_output=True, text=True)
            alignment_info['load_alignment']['file_info'] = file_result.stdout.strip()
            return alignment_info
        
        # åˆ†æå¯¹é½ä¿¡æ¯
        alignment_info['load_alignment']['raw_info'] = ''
        found_align = False
        max_align = 0
        
        for line in result.stdout.splitlines():
            # ä¿å­˜åŸå§‹è¾“å‡ºä¾›å‚è€ƒ
            if 'LOAD' in line:
                alignment_info['load_alignment']['raw_info'] += line + '\n'
                
                # å°è¯•è§£æå¯¹é½å€¼ï¼Œæ ¼å¼å¯èƒ½æ˜¯ "Align 0x1000" 
                align_match = re.search(r'Align\s+(0x[0-9a-fA-F]+)', line)
                if align_match:
                    align_str = align_match.group(1)
                    align_value = int(align_str, 16)
                    # ä¿å­˜æœ€å¤§çš„å¯¹é½å€¼
                    if align_value > max_align:
                        max_align = align_value
                        alignment_info['load_alignment']['alignment'] = align_str
                        alignment_info['load_alignment']['alignment_bytes'] = align_value
                        found_align = True
        
        # å¦‚æœæ— æ³•ä»readelfè¾“å‡ºä¸­è§£æå¯¹é½ä¿¡æ¯ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•
        if not found_align:
            # å°è¯•ä»fileå‘½ä»¤è·å–ä¸€äº›ä¿¡æ¯
            file_result = subprocess.run(['file', file_path], capture_output=True, text=True)
            alignment_info['load_alignment']['file_info'] = file_result.stdout.strip()
            
            # å¤§å¤šæ•°ç°ä»£SOåº“ä½¿ç”¨4Kå¯¹é½
            alignment_info['load_alignment']['alignment'] = '0x1000'  # å‡è®¾4Kå¯¹é½
            alignment_info['load_alignment']['alignment_bytes'] = 4096
            alignment_info['load_alignment']['estimation_method'] = 'heuristic'
        
        # æ·»åŠ å¯¹é½è¯„ä¼°ä¿¡æ¯
        align_value = alignment_info['load_alignment'].get('alignment_bytes', 0)
        if align_value >= 65536:  # 64Kå¯¹é½
            alignment_info['load_alignment']['assessment'] = 'Excellent (64K alignment)'
        elif align_value >= 16384:  # 16Kå¯¹é½
            alignment_info['load_alignment']['assessment'] = 'Very Good (16K alignment)'
        elif align_value >= 4096:  # 4Kå¯¹é½
            alignment_info['load_alignment']['assessment'] = 'Good (4K alignment)'
        elif align_value >= 1024:  # 1Kå¯¹é½
            alignment_info['load_alignment']['assessment'] = 'Acceptable (1K alignment)'
        else:
            alignment_info['load_alignment']['assessment'] = f'Sub-optimal ({align_value} bytes alignment)'
        
        return alignment_info
    except Exception as e:
        return {'error': f'Error analyzing alignment: {str(e)}'}

def get_elf_header_info(file_path):
    """è·å–ELFå¤´ä¿¡æ¯"""
    try:
        ndk_root = os.environ.get('NDK_ROOT')
        if not ndk_root:
            readelf_cmd = 'readelf'
        else:
            readelf_cmd = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-readelf')
            if not os.path.exists(readelf_cmd):
                readelf_cmd = 'readelf'
        
        result = subprocess.run([readelf_cmd, '-h', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error getting ELF header info: {result.stderr}'}
        
        # è§£æELFå¤´ä¿¡æ¯
        header_info = {}
        for line in result.stdout.splitlines():
            line = line.strip()
            if ':' in line:
                key, value = line.split(':', 1)
                header_info[key.strip()] = value.strip()
        
        return header_info
    except Exception as e:
        return {'error': f'Error analyzing ELF header: {str(e)}'}

def get_section_info(file_path):
    """è·å–èŠ‚åŒºä¿¡æ¯"""
    try:
        ndk_root = os.environ.get('NDK_ROOT')
        if not ndk_root:
            readelf_cmd = 'readelf'
        else:
            readelf_cmd = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-readelf')
            if not os.path.exists(readelf_cmd):
                readelf_cmd = 'readelf'
        
        result = subprocess.run([readelf_cmd, '-S', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error getting section info: {result.stderr}'}
        
        # è§£æèŠ‚åŒºä¿¡æ¯
        sections = []
        lines = result.stdout.splitlines()
        header_found = False
        
        for line in lines:
            line = line.strip()
            if 'Section Headers:' in line:
                header_found = True
                continue
            
            if header_found and line and line[0] == '[' and ']' in line:
                parts = line.split()
                if len(parts) >= 7:
                    section = {
                        'index': parts[0].strip('[]'),
                        'name': parts[1],
                        'type': parts[2],
                        'address': parts[3],
                        'offset': parts[4],
                        'size': parts[5],
                    }
                    sections.append(section)
        
        # è®¡ç®—èŠ‚åŒºå¤§å°ç»Ÿè®¡
        total_size = 0
        section_sizes = {}
        
        for section in sections:
            try:
                size = int(section['size'], 16)
                total_size += size
                section_sizes[section['name']] = {
                    'size_hex': section['size'],
                    'size_bytes': size,
                    'size_human': format_size(size)
                }
            except ValueError:
                pass
        
        return {
            'total_sections': len(sections),
            'total_size': {
                'bytes': total_size,
                'human_readable': format_size(total_size)
            },
            'section_sizes': section_sizes,
            'sections': sections
        }
    except Exception as e:
        return {'error': f'Error analyzing sections: {str(e)}'}

def check_hash_style(file_path):
    """æ£€æŸ¥SOæ–‡ä»¶ä½¿ç”¨çš„å“ˆå¸Œæ ·å¼ï¼ˆGNU Hashæˆ–SysV Hashï¼‰
    
    å“ˆå¸Œè¡¨æ˜¯ELFæ–‡ä»¶ä¸­ç”¨äºç¬¦å·æŸ¥æ‰¾çš„æ•°æ®ç»“æ„ã€‚æœ‰ä¸¤ç§ä¸»è¦ç±»å‹ï¼š
    1. SysV Hashï¼ˆ.hashèŠ‚ï¼‰ï¼šä¼ ç»Ÿå“ˆå¸Œè¡¨ï¼Œå…¼å®¹æ‰€æœ‰Androidç‰ˆæœ¬
    2. GNU Hashï¼ˆ.gnu.hashèŠ‚ï¼‰ï¼šæ›´é«˜æ•ˆçš„å“ˆå¸Œè¡¨ï¼Œä½†éœ€è¦Android 6.0+
    
    ä¸åŒçš„é“¾æ¥æ ‡å¿—ä¼šå½±å“å“ˆå¸Œè¡¨çš„ç”Ÿæˆï¼š
    - --hash-style=sysvï¼šåªç”ŸæˆSysVå“ˆå¸Œè¡¨
    - --hash-style=gnuï¼šåªç”ŸæˆGNUå“ˆå¸Œè¡¨
    - --hash-style=bothï¼šåŒæ—¶ç”Ÿæˆä¸¤ç§å“ˆå¸Œè¡¨ï¼ˆå…¼å®¹æ€§å¥½ä½†æ–‡ä»¶æ›´å¤§ï¼‰
    
    Returns:
        dict: å“ˆå¸Œæ ·å¼åˆ†æç»“æœ
    """
    try:
        # è·å–readelfå‘½ä»¤
        ndk_root = os.environ.get('NDK_ROOT')
        if not ndk_root:
            readelf_cmd = 'readelf'
        else:
            readelf_cmd = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-readelf')
            if not os.path.exists(readelf_cmd):
                readelf_cmd = 'readelf'
        
        # ä½¿ç”¨readelf -Sæ£€æŸ¥èŠ‚åŒºåç§°
        result = subprocess.run([readelf_cmd, '-S', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error analyzing hash style: {result.stderr}'}
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨.gnu.hashå’Œ.hashèŠ‚
        has_gnu_hash = '.gnu.hash' in result.stdout
        has_sysv_hash = '.hash' in result.stdout
        
        # åˆ†æå“ˆå¸Œæ ·å¼
        if has_gnu_hash and has_sysv_hash:
            hash_style = 'both'
            compatibility = 'all'
            description = 'åŒæ—¶ä½¿ç”¨GNUå’ŒSysVå“ˆå¸Œè¡¨ (å…¼å®¹æ‰€æœ‰Androidç‰ˆæœ¬)'
            recommendation = 'å¦‚æœæœ€å°SDK â‰¥ 23 (Android 6.0)ï¼Œå¯ä½¿ç”¨ --hash-style=gnu å‡å°æ–‡ä»¶å¤§å°'
            link_flag = '-Wl,--hash-style=both'
        elif has_gnu_hash:
            hash_style = 'gnu'
            compatibility = 'â‰¥23 (Android 6.0+)'
            description = 'ä»…ä½¿ç”¨GNUå“ˆå¸Œè¡¨ (Android 6.0+)'
            recommendation = 'å¦‚æœéœ€è¦æ”¯æŒAndroid 5.xï¼Œéœ€æ”¹ç”¨ --hash-style=both'
            link_flag = '-Wl,--hash-style=gnu'
        elif has_sysv_hash:
            hash_style = 'sysv'
            compatibility = 'all'
            description = 'ä»…ä½¿ç”¨SysVå“ˆå¸Œè¡¨ (ä¼ ç»Ÿæ ¼å¼)'
            recommendation = 'å¦‚æœæœ€å°SDK â‰¥ 23 (Android 6.0)ï¼Œå»ºè®®ä½¿ç”¨ --hash-style=gnu å‡å°æ–‡ä»¶å¤§å°'
            link_flag = '-Wl,--hash-style=sysv'
        else:
            hash_style = 'unknown'
            compatibility = 'unknown'
            description = 'æœªæ£€æµ‹åˆ°å“ˆå¸Œè¡¨'
            recommendation = 'æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å…±äº«åº“'
            link_flag = 'unknown'
        
        return {
            'hash_style': hash_style,
            'compatibility': compatibility,
            'description': description,
            'recommendation': recommendation,
            'has_gnu_hash': has_gnu_hash,
            'has_sysv_hash': has_sysv_hash,
            'link_flag': link_flag,
            'sdk_impact': 'å“ˆå¸Œæ ·å¼å½±å“SOåº“å¤§å°å’Œç¬¦å·æŸ¥æ‰¾æ€§èƒ½'
        }
    except Exception as e:
        return {'error': f'Error analyzing hash style: {str(e)}'}

def check_relocation_packing(file_path):
    """æ£€æŸ¥SOæ–‡ä»¶æ˜¯å¦ä½¿ç”¨äº†é‡å®šä½è¡¨å‹ç¼©
    
    é‡å®šä½è¡¨å‹ç¼©ï¼ˆ--pack-dyn-relocs=androidï¼‰æ˜¯ä¸€ç§å‡å°SOåº“å¤§å°çš„æŠ€æœ¯ï¼š
    1. ä¼ ç»Ÿï¼šä½¿ç”¨.rel.dynæˆ–.rela.dynèŠ‚
    2. å‹ç¼©ï¼šä½¿ç”¨Androidæ ¼å¼çš„å‹ç¼©é‡å®šä½è¡¨ï¼ŒèŠ‚çº¦ç©ºé—´
    
    æ³¨æ„ï¼šå‹ç¼©é‡å®šä½è¡¨è¦æ±‚minSdk â‰¥ 23 (Android 6.0+)
    
    Returns:
        dict: é‡å®šä½è¡¨åˆ†æç»“æœ
    """
    try:
        # è·å–readelfå‘½ä»¤
        ndk_root = os.environ.get('NDK_ROOT')
        if not ndk_root:
            readelf_cmd = 'readelf'
        else:
            readelf_cmd = os.path.join(ndk_root, 'toolchains', 'llvm', 'prebuilt', 'darwin-x86_64', 'bin', 'llvm-readelf')
            if not os.path.exists(readelf_cmd):
                readelf_cmd = 'readelf'
        
        # ä½¿ç”¨readelf -Sæ£€æŸ¥èŠ‚åŒºåç§°
        result = subprocess.run([readelf_cmd, '-S', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error analyzing relocation packing: {result.stderr}'}
        
        # Androidé‡å®šä½è¡¨å‹ç¼©ä½¿ç”¨.relr.dynèŠ‚
        has_relr = '.relr.dyn' in result.stdout
        
        # ä¼ ç»Ÿé‡å®šä½è¡¨ä½¿ç”¨.rel.dynæˆ–.rela.dyn
        has_traditional_rel = '.rel.dyn' in result.stdout
        has_traditional_rela = '.rela.dyn' in result.stdout
        
        # è·å–é‡å®šä½è¡¨å¤§å°
        section_info = get_section_info(file_path)
        rel_size = 0
        relr_size = 0
        
        if 'section_sizes' in section_info:
            for section_name, size_info in section_info['section_sizes'].items():
                if section_name in ['.rel.dyn', '.rela.dyn']:
                    rel_size += size_info.get('size_bytes', 0)
                elif section_name == '.relr.dyn':
                    relr_size = size_info.get('size_bytes', 0)
        
        # åˆ†æé‡å®šä½è¡¨å‹ç¼©çŠ¶æ€
        if has_relr:
            reloc_packing = 'android'
            compatibility = 'â‰¥23 (Android 6.0+)'
            description = 'ä½¿ç”¨äº†Androidé‡å®šä½è¡¨å‹ç¼©'
            recommendation = 'ä¿æŒç°çŠ¶ï¼Œå·²ä½¿ç”¨ä¼˜åŒ–'
            link_flag = '-Wl,--pack-dyn-relocs=android'
        elif has_traditional_rel or has_traditional_rela:
            reloc_packing = 'none'
            compatibility = 'all'
            description = 'ä½¿ç”¨ä¼ ç»Ÿé‡å®šä½è¡¨'
            recommendation = 'å¦‚æœminSdk â‰¥ 23 (Android 6.0)ï¼Œå»ºè®®ä½¿ç”¨ --pack-dyn-relocs=android å‡å°æ–‡ä»¶å¤§å°'
            link_flag = 'æœªä½¿ç”¨ --pack-dyn-relocs=android'
        else:
            reloc_packing = 'unknown'
            compatibility = 'unknown'
            description = 'æœªæ£€æµ‹åˆ°é‡å®šä½è¡¨'
            recommendation = 'æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å…±äº«åº“'
            link_flag = 'unknown'
        
        return {
            'relocation_packing': reloc_packing,
            'compatibility': compatibility,
            'description': description,
            'recommendation': recommendation,
            'has_relr': has_relr,
            'has_traditional_rel': has_traditional_rel or has_traditional_rela,
            'rel_size': rel_size,
            'relr_size': relr_size,
            'link_flag': link_flag,
            'potential_savings': 'å¯¹äºå¤§å‹SOåº“ï¼Œå‹ç¼©é‡å®šä½è¡¨å¯å‡å°æ•°ç™¾KBå¤§å°'
        }
    except Exception as e:
        return {'error': f'Error analyzing relocation packing: {str(e)}'}

def analyze_clang_ndk_version(file_path):
    """åˆ†æSOæ–‡ä»¶ä¸­çš„Clangç‰ˆæœ¬ä¿¡æ¯å¹¶æ¨æ–­NDKç‰ˆæœ¬
    
    æ–¹æ³•ï¼š
    1. ä½¿ç”¨stringså·¥å…·æå–SOæ–‡ä»¶ä¸­çš„å­—ç¬¦ä¸²
    2. æŸ¥æ‰¾Clangç‰ˆæœ¬ä¿¡æ¯ï¼ˆå¦‚"clang version X.Y.Z"ï¼‰
    3. æŸ¥æ‰¾NDKç›¸å…³ä¿¡æ¯
    4. æ ¹æ®å·²çŸ¥çš„Clang/NDKç‰ˆæœ¬æ˜ å°„å…³ç³»æ¨æ–­NDKç‰ˆæœ¬
    
    Returns:
        dict: Clangå’ŒNDKç‰ˆæœ¬åˆ†æç»“æœ
    """
    # NDKç‰ˆæœ¬ä¸Clangç‰ˆæœ¬çš„æ˜ å°„å…³ç³»
    # æ¥æº: https://developer.android.com/ndk/guides/other_build_systems
    NDK_CLANG_MAPPING = {
        # NDKç‰ˆæœ¬: [clangç‰ˆæœ¬, llvmç‰ˆæœ¬]
        "r27": ["18.1.0", "18.1.0"],
        "r26": ["17.0.2", "17.0.6"],
        "r25": ["14.0.7", "14.0.1"],
        "r24": ["14.0.1", "14.0.1"],
        "r23": ["12.0.9", "12.0.9"],
        "r22": ["11.0.5", "11.0.5"],
        "r21": ["9.0.9", "9.0.9"],
        "r20": ["8.0.7", "8.0.7"],
        "r19": ["7.0.2", "7.0.2"],
        "r18": ["6.0.2", "6.0.2"],
        "r17": ["6.0.2", "6.0.2"],
        "r16": ["5.0.300080", "5.0.300080"],
        "r15": ["5.0.300080", "5.0.300080"],
        "r14": ["4.0.0", "4.0.0"],
        "r13": ["3.8.275480", "3.8.275480"],
        "r12": ["3.8.256229", "3.8.256229"],
    }
    
    try:
        # æå–SOæ–‡ä»¶ä¸­çš„å­—ç¬¦ä¸²
        result = subprocess.run(['strings', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error extracting strings from file: {result.stderr}'}
        
        content = result.stdout
        
        # åˆå§‹åŒ–ç»“æœ
        version_info = {
            'clang_version': 'unknown',
            'clang_version_full': 'unknown',
            'ndk_version': 'unknown',
            'ndk_version_certainty': 'unknown',
            'detection_method': 'unknown',
            'clang_indicators': [],
            'ndk_indicators': []
        }
        
        # 1. ç›´æ¥æŸ¥æ‰¾NDKç‰ˆæœ¬æ ‡è¯†
        ndk_direct_patterns = [
            r'Android NDK ([a-z][0-9]+[a-z]?)',
            r'NDK ([a-z][0-9]+[a-z]?)',
            r'android-ndk-([a-z][0-9]+[a-z]?)'
        ]
        
        for pattern in ndk_direct_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                version_info['ndk_version'] = matches[0]
                version_info['ndk_version_certainty'] = 'high'
                version_info['detection_method'] = 'direct'
                version_info['ndk_indicators'].append(f'Found direct NDK version: {matches[0]}')
                break
        
        # 2. æŸ¥æ‰¾Clangç‰ˆæœ¬
        clang_patterns = [
            r'clang version ([0-9]+\.[0-9]+\.[0-9]+)',
            r'clang-([0-9]+\.[0-9]+\.[0-9]+)'
        ]
        
        clang_version = None
        clang_version_full = None
        
        for pattern in clang_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                clang_version = matches[0]
                # æŸ¥æ‰¾å®Œæ•´çš„clangç‰ˆæœ¬è¡Œ
                for line in content.splitlines():
                    if f'clang version {clang_version}' in line:
                        clang_version_full = line.strip()
                        break
                version_info['clang_version'] = clang_version
                version_info['clang_version_full'] = clang_version_full or f'clang version {clang_version}'
                version_info['clang_indicators'].append(f'Found Clang version: {clang_version}')
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°Clangç‰ˆæœ¬ï¼Œå°è¯•åŒ¹é…LLVMç‰ˆæœ¬
        if not clang_version:
            llvm_patterns = [
                r'LLVM version ([0-9]+\.[0-9]+\.[0-9]+)',
                r'libLLVM-([0-9]+\.[0-9]+\.[0-9]+)'
            ]
            
            for pattern in llvm_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    llvm_version = matches[0]
                    version_info['llvm_version'] = llvm_version
                    version_info['clang_indicators'].append(f'Found LLVM version: {llvm_version}')
                    # é€šå¸¸Clangå’ŒLLVMç‰ˆæœ¬æ˜¯å¯¹åº”çš„
                    if not clang_version:
                        clang_version = llvm_version
                        version_info['clang_version'] = clang_version
                        version_info['clang_version_full'] = f'inferred from LLVM {llvm_version}'
                    break
        
        # 3. æ ¹æ®Clangç‰ˆæœ¬æ¨æ–­NDKç‰ˆæœ¬
        if clang_version and version_info['ndk_version'] == 'unknown':
            closest_ndk = None
            closest_diff = float('inf')
            
            clang_version_parts = [int(part) for part in clang_version.split('.')]
            
            for ndk, versions in NDK_CLANG_MAPPING.items():
                clang_ref = versions[0]
                clang_ref_parts = [int(part) for part in clang_ref.split('.')]
                
                # è®¡ç®—ç‰ˆæœ¬å·®å¼‚ï¼ˆåªæ¯”è¾ƒä¸»è¦å’Œæ¬¡è¦ç‰ˆæœ¬å·ï¼‰
                diff = abs(clang_version_parts[0] - clang_ref_parts[0]) * 100
                if len(clang_version_parts) > 1 and len(clang_ref_parts) > 1:
                    diff += abs(clang_version_parts[1] - clang_ref_parts[1])
                
                if diff < closest_diff:
                    closest_diff = diff
                    closest_ndk = ndk
            
            if closest_ndk:
                version_info['ndk_version'] = closest_ndk
                
                # ç¡®å®šå¯ä¿¡åº¦
                if closest_diff == 0:
                    version_info['ndk_version_certainty'] = 'high'
                elif closest_diff < 5:
                    version_info['ndk_version_certainty'] = 'medium'
                else:
                    version_info['ndk_version_certainty'] = 'low'
                
                version_info['detection_method'] = 'clang_inference'
                version_info['ndk_indicators'].append(
                    f'Inferred from Clang {clang_version} (maps to NDK {closest_ndk}, certainty: {version_info["ndk_version_certainty"]})'
                )
        
        # 4. æŸ¥æ‰¾Android APIçº§åˆ«
        api_patterns = [
            r'__ANDROID_API__=([0-9]+)',
            r'android-([0-9]+)'
        ]
        
        for pattern in api_patterns:
            matches = re.findall(pattern, content)
            if matches:
                version_info['android_api_level'] = matches[0]
                version_info['ndk_indicators'].append(f'Found Android API level: {matches[0]}')
                break
        
        # 5. æ£€æŸ¥NDKçš„å»ºè®®ç‰ˆæœ¬ï¼ˆæ ¹æ®å½“å‰æ—¥æœŸï¼‰
        current_date = datetime.now()
        if current_date.year >= 2024:
            recommended_ndk = "r27"
            recommended_reason = "æœ€æ–°ç¨³å®šç‰ˆæœ¬ (2024å¹´æ¨èç‰ˆæœ¬)"
        elif current_date.year >= 2023:
            recommended_ndk = "r26"
            recommended_reason = "2023å¹´æ¨èç‰ˆæœ¬"
        else:
            recommended_ndk = "r25"
            recommended_reason = "ç¨³å®šé•¿æœŸæ”¯æŒç‰ˆæœ¬"
        
        # æ·»åŠ æ¨èä¿¡æ¯
        version_info['recommended_ndk'] = recommended_ndk
        version_info['recommended_reason'] = recommended_reason
        
        # å¦‚æœæ£€æµ‹åˆ°çš„NDKç‰ˆæœ¬å°äºæ¨èç‰ˆæœ¬ï¼Œæ·»åŠ å‡çº§å»ºè®®
        if version_info['ndk_version'] != 'unknown' and version_info['ndk_version'] < recommended_ndk:
            version_info['upgrade_recommendation'] = f"å»ºè®®å‡çº§åˆ°NDK {recommended_ndk} ({recommended_reason})"
        
        # æ·»åŠ NDKæ˜ å°„è¡¨çš„å¼•ç”¨ï¼ˆä¾›å‚è€ƒï¼‰
        version_info['ndk_clang_reference'] = {
            "reference": "NDKä¸Clangç‰ˆæœ¬å¯¹åº”å…³ç³»",
            "mapping": NDK_CLANG_MAPPING
        }
        
        return version_info
    except Exception as e:
        return {'error': f'Error analyzing Clang/NDK version: {str(e)}'}

def get_optimization_level(file_path):
    """å°è¯•æ£€æµ‹SOæ–‡ä»¶çš„ä¼˜åŒ–çº§åˆ«"""
    try:
        result = subprocess.run(['strings', file_path], capture_output=True, text=True)
        
        if result.returncode != 0:
            return {'error': f'Error analyzing optimization: {result.stderr}'}
        
        content = result.stdout.lower()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è°ƒè¯•ä¿¡æ¯
        has_debug_info = '.debug_info' in content or '.debug_str' in content
        
        # æ£€æŸ¥ç¼–è¯‘ä¼˜åŒ–çº§åˆ«çš„æ ‡è®°
        optimization = 'unknown'
        if '-o0' in content:
            optimization = 'O0 (No optimization)'
        elif '-o1' in content:
            optimization = 'O1 (Basic optimization)'
        elif '-o2' in content:
            optimization = 'O2 (Medium optimization)'
        elif '-o3' in content:
            optimization = 'O3 (High optimization)'
        elif '-os' in content:
            optimization = 'Os (Size optimization)'
        elif '-oz' in content:
            optimization = 'Oz (More size optimization)'
        
        # æ£€æŸ¥æ˜¯å¦æœ‰stripè¿‡çš„æ ‡è®°
        is_stripped = not has_debug_info
        
        return {
            'optimization_level': optimization,
            'has_debug_info': has_debug_info,
            'is_stripped': is_stripped
        }
    except Exception as e:
        return {'error': f'Error analyzing optimization: {str(e)}'}

def align_so_file(file_path, alignment=16384, output_path=None):
    """å¯¹é½SOæ–‡ä»¶åˆ°æŒ‡å®šè¾¹ç•Œ
    
    Args:
        file_path: åŸå§‹SOæ–‡ä»¶è·¯å¾„
        alignment: å¯¹é½è¾¹ç•Œ (é»˜è®¤16KB)
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤è¦†ç›–åŸæ–‡ä»¶)
    
    Returns:
        dict: å¯¹é½ç»“æœä¿¡æ¯
    """
    if not os.path.exists(file_path):
        return {'error': f'æ–‡ä»¶ä¸å­˜åœ¨: {file_path}'}
    
    if not file_path.endswith('.so'):
        return {'error': f'ä¸æ˜¯SOæ–‡ä»¶: {file_path}'}
    
    # è·å–åŸå§‹æ–‡ä»¶å¤§å°
    original_size = os.path.getsize(file_path)
    
    # è®¡ç®—å¯¹é½åçš„æ–‡ä»¶å¤§å°
    aligned_size = ((original_size + alignment - 1) // alignment) * alignment
    padding_needed = aligned_size - original_size
    
    if padding_needed == 0:
        return {
            'status': 'already_aligned',
            'original_size': original_size,
            'alignment': alignment,
            'message': f'æ–‡ä»¶å·²æŒ‰ {alignment} å­—èŠ‚å¯¹é½'
        }
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
    if output_path is None:
        output_path = file_path + '.aligned'
    
    try:
        # å¤åˆ¶æ–‡ä»¶å¹¶æ·»åŠ å¡«å……
        with open(file_path, 'rb') as src:
            with open(output_path, 'wb') as dst:
                # å¤åˆ¶åŸå§‹å†…å®¹
                dst.write(src.read())
                # æ·»åŠ å¡«å…… (é€šå¸¸å¡«å……0æˆ–NOPæŒ‡ä»¤)
                dst.write(b'\x00' * padding_needed)
        
        return {
            'status': 'aligned',
            'original_size': original_size,
            'aligned_size': aligned_size,
            'padding_added': padding_needed,
            'alignment': alignment,
            'output_path': output_path,
            'message': f'æˆåŠŸå¯¹é½æ–‡ä»¶ï¼Œæ·»åŠ äº† {padding_needed} å­—èŠ‚å¡«å……'
        }
        
    except Exception as e:
        return {'error': f'å¯¹é½å¤±è´¥: {str(e)}'}

def analyze_so_file(file_path):
    """å…¨é¢åˆ†æSOæ–‡ä»¶"""
    if not os.path.exists(file_path):
        return {'error': f'File not found: {file_path}'}
    
    if not file_path.endswith('.so'):
        return {'error': f'Not a .so file: {file_path}'}
    
    # æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
    results = {
        'basic_info': get_file_basic_info(file_path),
        'architecture': get_so_architecture(file_path),
        'exported_symbols': get_exported_symbols(file_path),
        'dependencies': get_dependencies(file_path),
        'alignment': check_alignment(file_path),
        'elf_header': get_elf_header_info(file_path),
        'section_info': get_section_info(file_path),
        'optimization': get_optimization_level(file_path),
        'hash_style': check_hash_style(file_path),               # æ–°å¢ï¼šå“ˆå¸Œæ ·å¼åˆ†æ
        'relocation_packing': check_relocation_packing(file_path), # æ–°å¢ï¼šé‡å®šä½è¡¨å‹ç¼©åˆ†æ
        'ndk_version': analyze_clang_ndk_version(file_path)      # æ–°å¢ï¼šNDKç‰ˆæœ¬åˆ†æ
    }
    
    return results

def analyze_directory(dir_path):
    """åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰SOæ–‡ä»¶"""
    if not os.path.exists(dir_path):
        return {'error': f'Directory not found: {dir_path}'}
    
    results = {}
    so_files = []
    
    # éå†ç›®å½•æŸ¥æ‰¾æ‰€æœ‰SOæ–‡ä»¶
    for root, _, files in os.walk(dir_path):
        for file in files:
            if file.endswith('.so'):
                so_path = os.path.join(root, file)
                so_files.append(so_path)
    
    if not so_files:
        return {'error': f'No .so files found in directory: {dir_path}'}
    
    # åˆ†ææ¯ä¸ªSOæ–‡ä»¶
    for so_file in so_files:
        relative_path = os.path.relpath(so_file, dir_path)
        results[relative_path] = analyze_so_file(so_file)
    
    # æ·»åŠ ç›®å½•æ¦‚è§ˆä¿¡æ¯
    results['summary'] = {
        'total_so_files': len(so_files),
        'directory': dir_path,
        'so_files': so_files
    }
    
    return results

def main():
    parser = argparse.ArgumentParser(
        description='Android SOæ–‡ä»¶åˆ†æå·¥å…· - å…¨é¢åˆ†æAndroid SOåº“æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s libnative.so                    # åˆ†æå•ä¸ªSOæ–‡ä»¶
  %(prog)s /path/to/libs -v                # è¯¦ç»†åˆ†æç›®å½•
  %(prog)s lib.so --symbols all            # æ˜¾ç¤ºæ‰€æœ‰ç¬¦å·
  %(prog)s lib.so -c --no-color            # ç´§å‡‘æ— è‰²è¾“å‡º
  %(prog)s lib.so -o result.json           # ä¿å­˜JSONç»“æœ
  %(prog)s lib.so --align 16384            # å¯¹é½åˆ°16KBè¾¹ç•Œ
  %(prog)s lib.so --align 65536 --align-output aligned.so  # å¯¹é½å¹¶æŒ‡å®šè¾“å‡º

ç¬¦å·ç±»å‹è¯´æ˜:
  T: å¯¼å‡ºå‡½æ•°    W: å¼±ç¬¦å·    R: åªè¯»æ•°æ®
  D: åˆå§‹åŒ–æ•°æ®  B: æœªåˆå§‹åŒ–æ•°æ® (BSS)
  U: æœªå®šä¹‰ç¬¦å·  V: å¼±å¯¹è±¡

å“ˆå¸Œæ ·å¼è¯´æ˜:
  gnu: ä»…GNUå“ˆå¸Œè¡¨ (Android 6.0+ï¼Œæ›´å°æ›´å¿«)
  sysv: ä»…SysVå“ˆå¸Œè¡¨ (å…¼å®¹æ‰€æœ‰Androidç‰ˆæœ¬)
  both: åŒæ—¶ä½¿ç”¨ä¸¤ç§å“ˆå¸Œè¡¨ (å…¼å®¹æ‰€æœ‰ç‰ˆæœ¬ä½†æ›´å¤§)

é‡å®šä½è¡¨å‹ç¼©è¯´æ˜:
  android: ä½¿ç”¨Androidå‹ç¼©æ ¼å¼ (Android 6.0+ï¼Œå¯å‡å°å‡ ç™¾KB)
  none: ä½¿ç”¨ä¼ ç»Ÿé‡å®šä½è¡¨ (å…¼å®¹æ‰€æœ‰Androidç‰ˆæœ¬)
        """
    )
    parser.add_argument('path', help='SOæ–‡ä»¶æˆ–åŒ…å«SOæ–‡ä»¶çš„ç›®å½•è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-v', '--verbose', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    parser.add_argument('-c', '--compact', action='store_true', help='ç´§å‡‘è¾“å‡ºæ¨¡å¼')
    parser.add_argument('--symbols', choices=['exported', 'all'], default='exported', 
                       help='æ˜¾ç¤ºç¬¦å·ç±»å‹ (é»˜è®¤: exported)')
    parser.add_argument('--filter-symbol-type', help='æŒ‰ç¬¦å·ç±»å‹è¿‡æ»¤ (ä¾‹å¦‚: T, W, R, D, B, U, V)')
    parser.add_argument('--align', type=int, choices=[4096, 8192, 16384, 32768, 65536], 
                       help='å¯¹é½SOæ–‡ä»¶åˆ°æŒ‡å®šè¾¹ç•Œ (å­—èŠ‚)')
    parser.add_argument('--align-output', help='å¯¹é½åæ–‡ä»¶è¾“å‡ºè·¯å¾„')
    parser.add_argument('--max-symbols', type=int, default=20, help='æœ€å¤šæ˜¾ç¤ºçš„ç¬¦å·æ•°é‡ (é»˜è®¤: 20)')
    parser.add_argument('--no-color', action='store_true', help='ç¦ç”¨å½©è‰²è¾“å‡º')
    args = parser.parse_args()
    
    # å¦‚æœç¦ç”¨é¢œè‰²ï¼Œè¦†ç›–colorizeå‡½æ•°
    if args.no_color:
        global colorize
        colorize = lambda text, color_code: text
    
    # æ£€æŸ¥NDKç¯å¢ƒå˜é‡
    if 'NDK_ROOT' not in os.environ:
        print_warning("NDK_ROOTç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼ŒæŸäº›åˆ†æåŠŸèƒ½å¯èƒ½å—é™")
    
    # åˆ†ææ–‡ä»¶æˆ–ç›®å½•
    path = os.path.abspath(args.path)
    
    # å¤„ç†å¯¹é½æ“ä½œ
    if args.align:
        print_header("ğŸ”§ SOæ–‡ä»¶å¯¹é½å·¥å…·")
        result = align_so_file(path, args.align, args.align_output)
        if 'error' in result:
            print_error(f"å¯¹é½å¤±è´¥: {result['error']}")
        else:
            print_success(result['message'])
            print_info("åŸå§‹å¤§å°", f"{result['original_size']:,} å­—èŠ‚")
            print_info("å¯¹é½åå¤§å°", f"{result['aligned_size']:,} å­—èŠ‚")
            if result['status'] == 'aligned':
                print_info("å¡«å……å¤§å°", f"{result['padding_added']:,} å­—èŠ‚")
            if 'output_path' in result:
                print_info("è¾“å‡ºæ–‡ä»¶", result['output_path'])
        return
    if os.path.isfile(path):
        if not args.compact:
            print_header("ğŸ” ANDROID SOåˆ†æå·¥å…·")
            print_info("åˆ†ææ—¶é—´", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
            print_info("ç³»ç»Ÿç¯å¢ƒ", f"{platform.system()} {platform.release()} ({platform.machine()})")
        results = analyze_so_file(path)
    else:
        if not args.compact:
            print_header("ğŸ” ANDROID SOç›®å½•åˆ†æå·¥å…·")
            print_info("åˆ†ææ—¶é—´", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
            print_info("ç³»ç»Ÿç¯å¢ƒ", f"{platform.system()} {platform.release()} ({platform.machine()})")
        results = analyze_directory(path)
    
    # è¾“å‡ºç»“æœ
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print_success(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    else:
        # æ‰“å°ç»“æœæ‘˜è¦
        if 'error' in results:
            print_error(f"é”™è¯¯: {results['error']}")
        elif 'summary' in results:
            # ç›®å½•åˆ†ææ‘˜è¦
            if not args.compact:
                print_header("ğŸ“ ç›®å½•åˆ†ææ‘˜è¦")
            print_info("ç›®å½•è·¯å¾„", results['summary']['directory'])
            print_info("SOæ–‡ä»¶æ•°é‡", str(results['summary']['total_so_files']))
            
            if not args.compact:
                print_subheader("ğŸ“‹ SOæ–‡ä»¶åˆ—è¡¨")
            for idx, so_file in enumerate(results['summary']['so_files'], 1):
                rel_path = os.path.relpath(so_file, path)
                so_info = results[rel_path]
                if 'error' in so_info:
                    print_error(f"{idx}. {rel_path} - åˆ†æé”™è¯¯: {so_info['error']}")
                else:
                    arch = so_info['architecture'].get('architecture', 'unknown')
                    size = so_info['basic_info']['file_size']['human_readable']
                    deps = so_info['dependencies'].get('total_dependencies', 0)
                    if args.compact:
                        print_info(f"{idx}. {rel_path}", f"{arch}, {size}, ä¾èµ–:{deps}", "0;36")
                    else:
                        print_info(f"{idx}. {rel_path}", f"{arch}, {size}, ä¾èµ–: {deps}ä¸ªåº“", "0;36")
        else:
            # å•æ–‡ä»¶åˆ†ææ‘˜è¦
            basic_info = results['basic_info']
            arch_info = results['architecture']
            symbols_info = results['exported_symbols']
            deps_info = results['dependencies']
            align_info = results['alignment']
            opt_info = results['optimization']
            
            print_header("ğŸ“Š SOæ–‡ä»¶åˆ†ææŠ¥å‘Š")
            
            # åŸºæœ¬ä¿¡æ¯éƒ¨åˆ†
            if not args.compact:
                print_subheader("ğŸ“Œ åŸºæœ¬ä¿¡æ¯")
            print_info("æ–‡ä»¶åç§°", basic_info['file_name'])
            print_info("æ–‡ä»¶å¤§å°", basic_info['file_size']['human_readable'])
            print_info("æ¶æ„ç±»å‹", arch_info.get('architecture', 'unknown'))
            
            # å“ˆå¸Œå€¼éƒ¨åˆ†
            if not args.compact:
                print_subheader("ğŸ” å“ˆå¸Œå€¼")
            print_info("MD5", basic_info['md5'])
            print_info("SHA1", basic_info['sha1'])
            print_info("SHA256", basic_info['sha256'][:32] + "...")
            
            # å¯¼å‡ºç¬¦å·éƒ¨åˆ†
            print_subheader("ğŸ”£ ç¬¦å·ä¿¡æ¯")
            if 'error' in symbols_info:
                print_error(f"ç¬¦å·åˆ†æå¤±è´¥: {symbols_info['error']}")
            else:
                print_info("æ‰€æœ‰ç¬¦å·æ€»æ•°", str(symbols_info.get('total_symbols', 'unknown')))
                print_info("å¯¼å‡ºç¬¦å·æ€»æ•°", str(symbols_info.get('total_exported_symbols', 'unknown')), "1;33")
                
                # å¯¼å‡ºç¬¦å·ç±»å‹ç»Ÿè®¡
                if 'exported_symbol_stats_list' in symbols_info and symbols_info['exported_symbol_stats_list']:
                    print_info("å¯¼å‡ºç¬¦å·ç±»å‹ç»Ÿè®¡", "", "1;33")
                    headers = ["ç±»å‹", "æ•°é‡", "æè¿°"]
                    rows = []
                    for stat in symbols_info['exported_symbol_stats_list']:
                        rows.append([
                            stat['type'], 
                            stat['count'], 
                            stat['description']
                        ])
                    print_table(headers, rows)
                
                # æ‰€æœ‰ç¬¦å·ç±»å‹ç»Ÿè®¡
                if 'symbol_stats_list' in symbols_info and symbols_info['symbol_stats_list'] and args.verbose:
                    print_info("æ‰€æœ‰ç¬¦å·ç±»å‹ç»Ÿè®¡", "")
                    headers = ["ç±»å‹", "æ•°é‡", "æè¿°"]
                    rows = []
                    for stat in symbols_info['symbol_stats_list']:
                        rows.append([
                            stat['type'], 
                            stat['count'], 
                            stat['description']
                        ])
                    print_table(headers, rows)
                
                # å¦‚æœç”¨æˆ·è¯·æ±‚æ˜¾ç¤ºè¯¦ç»†ç¬¦å·ä¿¡æ¯
                if (args.symbols in ['exported', 'all'] or args.filter_symbol_type) and not args.compact:
                    print_subheader("ğŸ” è¯¦ç»†ç¬¦å·åˆ—è¡¨")
                elif (args.symbols in ['exported', 'all'] or args.filter_symbol_type) and args.compact:
                    print_info("ç¬¦å·è¯¦æƒ…", "æ˜¾ç¤ºä¸­...")
                
                if args.symbols in ['exported', 'all'] or args.filter_symbol_type:
                    # æ ¹æ®å‚æ•°é€‰æ‹©æ˜¾ç¤ºçš„ç¬¦å·
                    if args.symbols == 'all':
                        symbols_to_show = symbols_info['symbols']
                        if not args.compact:
                            print_info("æ˜¾ç¤ºç±»å‹", "æ‰€æœ‰ç¬¦å·")
                    else:
                        symbols_to_show = symbols_info['exported_symbols']
                        if not args.compact:
                            print_info("æ˜¾ç¤ºç±»å‹", "å¯¼å‡ºç¬¦å·", "1;33")
                    
                    if args.filter_symbol_type:
                        if not args.compact:
                            print_info("è¿‡æ»¤ç±»å‹", f"{args.filter_symbol_type} - {get_symbol_type_description(args.filter_symbol_type)}")
                    
                    # æ˜¾ç¤ºç¬¦å·åˆ—è¡¨
                    show_all = (args.symbols == 'all' and not args.filter_symbol_type) or (args.max_symbols is None)
                    print_symbol_details(
                        symbols_to_show, 
                        max_symbols=None if show_all else args.max_symbols,
                        filter_type=args.filter_symbol_type,
                        show_all=show_all
                    )
            
            # ä¾èµ–åº“éƒ¨åˆ†
            if not args.compact:
                print_subheader("ğŸ”— ä¾èµ–åº“")
            if 'error' in deps_info:
                print_error(f"ä¾èµ–åˆ†æå¤±è´¥: {deps_info['error']}")
            else:
                deps_count = deps_info.get('total_dependencies', 0)
                print_info("ä¾èµ–åº“æ•°é‡", str(deps_count))
                if deps_count > 0:
                    if args.compact:
                        # ç´§å‡‘æ¨¡å¼ï¼šä¸€è¡Œæ˜¾ç¤ºæ‰€æœ‰ä¾èµ–
                        deps_list = deps_info.get('dependencies', [])
                        print_info("ä¾èµ–åˆ—è¡¨", ", ".join(deps_list))
                    else:
                        for idx, dep in enumerate(deps_info.get('dependencies', []), 1):
                            print_info(f"  {idx}.", dep)
            
            # å¯¹é½ä¿¡æ¯éƒ¨åˆ†
            print_subheader("ğŸ“ å¯¹é½ä¿¡æ¯")
            if 'error' in align_info:
                print_error(f"å¯¹é½åˆ†æå¤±è´¥: {align_info['error']}")
            else:
                # ZIPå¯¹é½ä¿¡æ¯
                zip_align = align_info.get('zip_alignment', {})
                if zip_align:
                    zip_status = "âœ… å·²å¯¹é½" if zip_align.get('is_aligned', False) else "âŒ æœªå¯¹é½"
                    zip_value = zip_align.get('alignment_human', 'unknown')
                    print_info("ZIPå¯¹é½", f"{zip_value} {zip_status}", "1;32" if zip_align.get('is_aligned', False) else "1;31")
                    
                    if not args.compact:
                        purpose = zip_align.get('purpose', '')
                        benefit = zip_align.get('benefit', '')
                        if purpose:
                            print_info("å¯¹é½ç›®çš„", purpose, "0;36")
                        if benefit:
                            print_info("æ€§èƒ½ç›Šå¤„", benefit, "0;36")
                    
                    if not zip_align.get('is_aligned', False) and 'remainder' in zip_align:
                        remainder_kb = zip_align['remainder'] / 1024
                        print_info("åç§»é‡", f"{remainder_kb:.1f} KB", "1;33")
                        if not args.compact and 'recommendation' in zip_align:
                            print_info("ä¿®å¤å»ºè®®", zip_align['recommendation'], "1;33")
                
                # LOADæ®µå¯¹é½ä¿¡æ¯
                load_align = align_info.get('load_alignment', {})
                if load_align:
                    load_value = load_align.get('alignment', 'unknown')
                    load_bytes = load_align.get('alignment_bytes', 'unknown')
                    load_power = load_align.get('alignment_power', None)
                    assess = load_align.get('assessment', 'unknown')
                    
                    if load_bytes != 'unknown':
                        if load_power:
                            print_info("LOADæ®µå¯¹é½", f"{load_value} (2^{load_power} = {load_bytes} å­—èŠ‚)")
                        else:
                            print_info("LOADæ®µå¯¹é½", f"{load_value} ({load_bytes} å­—èŠ‚)")
                    else:
                        print_info("LOADæ®µå¯¹é½", load_value)
                        
                    # æ ¹æ®è¯„ä¼°ç»“æœé€‰æ‹©é¢œè‰²
                    color = "0;32"  # é»˜è®¤ç»¿è‰²
                    if "Excellent" in assess:
                        color = "1;32"  # äº®ç»¿è‰²
                    elif "Very Good" in assess:
                        color = "0;32"  # ç»¿è‰²
                    elif "Good" in assess:
                        color = "0;36"  # é’è‰²
                    elif "Acceptable" in assess:
                        color = "1;33"  # äº®é»„è‰²
                    elif "Sub-optimal" in assess:
                        color = "1;31"  # äº®çº¢è‰²
                        
                    print_info("å¯¹é½è¯„ä¼°", assess, color)
                
                # ç»¼åˆå»ºè®®
                zip_aligned = align_info.get('zip_alignment', {}).get('is_aligned', False)
                load_assess = align_info.get('load_alignment', {}).get('assessment', '')
                if zip_aligned and "Excellent" in load_assess:
                    print_info("ç»¼åˆè¯„ä¼°", "å®Œç¾å¯¹é½ (ZIP + LOAD)", "1;32")
                elif zip_aligned:
                    print_info("ç»¼åˆè¯„ä¼°", "ZIPå¯¹é½è‰¯å¥½", "0;32")
                else:
                    print_info("ç»¼åˆè¯„ä¼°", "å»ºè®®é‡æ–°å¯¹é½", "1;33")
            
            # ä¼˜åŒ–ä¿¡æ¯éƒ¨åˆ†
            if not args.compact:
                print_subheader("âš™ï¸ ä¼˜åŒ–ä¿¡æ¯")
            if 'error' in opt_info:
                print_error(f"ä¼˜åŒ–åˆ†æå¤±è´¥: {opt_info['error']}")
            else:
                opt_level = opt_info.get('optimization_level', 'unknown')
                has_debug = opt_info.get('has_debug_info', False)
                is_stripped = opt_info.get('is_stripped', False)
                
                if args.compact:
                    debug_str = "æœ‰è°ƒè¯•" if has_debug else "æ— è°ƒè¯•"
                    stripped_str = "å·²å‰¥ç¦»" if is_stripped else "æœªå‰¥ç¦»"
                    print_info("ä¼˜åŒ–çŠ¶æ€", f"{opt_level}, {debug_str}, {stripped_str}")
                else:
                    print_info("ä¼˜åŒ–çº§åˆ«", opt_level)
                    print_info("åŒ…å«è°ƒè¯•ä¿¡æ¯", "æ˜¯" if has_debug else "å¦")
                    print_info("å·²å‰¥ç¦»ç¬¦å·", "æ˜¯" if is_stripped else "å¦")
            
            # å“ˆå¸Œæ ·å¼éƒ¨åˆ†ï¼ˆæ–°å¢ï¼‰
            hash_info = results.get('hash_style', {})
            print_subheader("ğŸ”„ å“ˆå¸Œæ ·å¼ (Hash Style)")
            if 'error' in hash_info:
                print_error(f"å“ˆå¸Œæ ·å¼åˆ†æå¤±è´¥: {hash_info['error']}")
            else:
                hash_style = hash_info.get('hash_style', 'unknown')
                compatibility = hash_info.get('compatibility', 'unknown')
                description = hash_info.get('description', '')
                
                # é€‰æ‹©åˆé€‚çš„é¢œè‰²
                hash_color = "0;32"  # é»˜è®¤ç»¿è‰²
                if hash_style == 'gnu':
                    hash_color = "1;32"  # äº®ç»¿è‰²ï¼ˆæœ€ä¼˜ï¼‰
                elif hash_style == 'both':
                    hash_color = "1;33"  # äº®é»„è‰²ï¼ˆå…¼å®¹ä½†ä¸æ˜¯æœ€ä¼˜ï¼‰
                elif hash_style == 'sysv':
                    hash_color = "1;31"  # äº®çº¢è‰²ï¼ˆä¸æ˜¯æœ€ä¼˜ï¼‰
                
                print_info("å“ˆå¸Œæ ·å¼", hash_style, hash_color)
                print_info("å…¼å®¹æ€§", f"Android API {compatibility}")
                print_info("æè¿°", description)
                
                if not args.compact:
                    if 'recommendation' in hash_info:
                        print_info("å»ºè®®", hash_info['recommendation'], "1;36")
                    if 'link_flag' in hash_info:
                        print_info("é“¾æ¥æ ‡å¿—", hash_info['link_flag'], "0;36")
            
            # é‡å®šä½è¡¨å‹ç¼©éƒ¨åˆ†ï¼ˆæ–°å¢ï¼‰
            reloc_info = results.get('relocation_packing', {})
            print_subheader("ğŸ“¦ é‡å®šä½è¡¨å‹ç¼© (Relocation Packing)")
            if 'error' in reloc_info:
                print_error(f"é‡å®šä½è¡¨åˆ†æå¤±è´¥: {reloc_info['error']}")
            else:
                reloc_packing = reloc_info.get('relocation_packing', 'unknown')
                compatibility = reloc_info.get('compatibility', 'unknown')
                description = reloc_info.get('description', '')
                
                # é€‰æ‹©åˆé€‚çš„é¢œè‰²
                reloc_color = "0;32"  # é»˜è®¤ç»¿è‰²
                if reloc_packing == 'android':
                    reloc_color = "1;32"  # äº®ç»¿è‰²ï¼ˆæœ€ä¼˜ï¼‰
                elif reloc_packing == 'none':
                    reloc_color = "1;31"  # äº®çº¢è‰²ï¼ˆä¸æ˜¯æœ€ä¼˜ï¼‰
                
                print_info("é‡å®šä½å‹ç¼©", reloc_packing, reloc_color)
                print_info("å…¼å®¹æ€§", f"Android API {compatibility}")
                print_info("æè¿°", description)
                
                # æ˜¾ç¤ºé‡å®šä½è¡¨å¤§å°ï¼ˆå¦‚æœæœ‰ï¼‰
                rel_size = reloc_info.get('rel_size', 0)
                relr_size = reloc_info.get('relr_size', 0)
                if rel_size or relr_size:
                    if rel_size > 0:
                        print_info("ä¼ ç»Ÿé‡å®šä½è¡¨å¤§å°", format_size(rel_size))
                    if relr_size > 0:
                        print_info("å‹ç¼©é‡å®šä½è¡¨å¤§å°", format_size(relr_size))
                
                if not args.compact:
                    if 'recommendation' in reloc_info:
                        print_info("å»ºè®®", reloc_info['recommendation'], "1;36")
                    if 'link_flag' in reloc_info:
                        print_info("é“¾æ¥æ ‡å¿—", reloc_info['link_flag'], "0;36")
            
            # NDKç‰ˆæœ¬åˆ†æéƒ¨åˆ†ï¼ˆæ–°å¢ï¼‰
            ndk_info = results.get('ndk_version', {})
            print_subheader("ğŸ› ï¸ NDKç‰ˆæœ¬åˆ†æ")
            if 'error' in ndk_info:
                print_error(f"NDKç‰ˆæœ¬åˆ†æå¤±è´¥: {ndk_info['error']}")
            else:
                ndk_version = ndk_info.get('ndk_version', 'unknown')
                ndk_certainty = ndk_info.get('ndk_version_certainty', 'unknown')
                clang_version = ndk_info.get('clang_version', 'unknown')
                clang_version_full = ndk_info.get('clang_version_full', '')
                detection_method = ndk_info.get('detection_method', '')
                
                # é€‰æ‹©åˆé€‚çš„é¢œè‰²
                certainty_color = "0;32"  # é»˜è®¤ç»¿è‰²
                if ndk_certainty == 'high':
                    certainty_color = "1;32"  # äº®ç»¿è‰²ï¼ˆé«˜å¯ä¿¡åº¦ï¼‰
                elif ndk_certainty == 'medium':
                    certainty_color = "1;33"  # äº®é»„è‰²ï¼ˆä¸­ç­‰å¯ä¿¡åº¦ï¼‰
                elif ndk_certainty == 'low':
                    certainty_color = "1;31"  # äº®çº¢è‰²ï¼ˆä½å¯ä¿¡åº¦ï¼‰
                
                print_info("æ£€æµ‹åˆ°çš„NDKç‰ˆæœ¬", ndk_version, certainty_color)
                if ndk_certainty != 'unknown':
                    print_info("å¯ä¿¡åº¦", ndk_certainty, certainty_color)
                
                if clang_version != 'unknown':
                    print_info("Clangç‰ˆæœ¬", clang_version)
                    if not args.compact and clang_version_full:
                        print_info("Clangè¯¦ç»†ä¿¡æ¯", clang_version_full, "0;36")
                
                # æ˜¾ç¤ºAPIçº§åˆ«
                if 'android_api_level' in ndk_info:
                    print_info("Android APIçº§åˆ«", ndk_info['android_api_level'])
                
                # æ¨èä¿¡æ¯
                if 'recommended_ndk' in ndk_info:
                    recommended_ndk = ndk_info['recommended_ndk']
                    recommended_reason = ndk_info.get('recommended_reason', '')
                    
                    # å½“å‰NDKæ˜¯å¦ä¸ºæ¨èç‰ˆæœ¬
                    if ndk_version == recommended_ndk:
                        print_info("NDKç‰ˆæœ¬çŠ¶æ€", f"å½“å‰ç‰ˆæœ¬ ({recommended_ndk}) å·²æ˜¯æ¨èç‰ˆæœ¬", "1;32")
                    else:
                        print_info("æ¨èNDKç‰ˆæœ¬", recommended_ndk, "1;36")
                        if recommended_reason:
                            print_info("æ¨èåŸå› ", recommended_reason, "0;36")
                
                # æ˜¾ç¤ºå‡çº§å»ºè®®
                if 'upgrade_recommendation' in ndk_info:
                    print_info("å‡çº§å»ºè®®", ndk_info['upgrade_recommendation'], "1;33")
                
                # æ˜¾ç¤ºæ¨æ–­è¿‡ç¨‹çš„æ›´å¤šä¿¡æ¯ï¼ˆè¯¦ç»†æ¨¡å¼ï¼‰
                if args.verbose:
                    # æ˜¾ç¤ºæ¨æ–­è¿‡ç¨‹çš„æŒ‡æ ‡
                    indicators = ndk_info.get('ndk_indicators', [])
                    if indicators:
                        print_info("NDKç‰ˆæœ¬æ£€æµ‹æŒ‡æ ‡", '')
                        for idx, indicator in enumerate(indicators, 1):
                            print(f"    {idx}. {indicator}")
                    
                    clang_indicators = ndk_info.get('clang_indicators', [])
                    if clang_indicators:
                        print_info("Clangç‰ˆæœ¬æ£€æµ‹æŒ‡æ ‡", '')
                        for idx, indicator in enumerate(clang_indicators, 1):
                            print(f"    {idx}. {indicator}")
            
            # æç¤ºä¿¡æ¯
            if not args.compact:
                print("\næç¤º:")
                print(f"  ä½¿ç”¨ -o å‚æ•°ä¿å­˜å®Œæ•´JSONç»“æœ")
                print(f"  ä½¿ç”¨ --symbols all æŸ¥çœ‹æ‰€æœ‰ç¬¦å·è¯¦æƒ…")
                print(f"  ä½¿ç”¨ --filter-symbol-type T åªæŸ¥çœ‹å¯¼å‡ºå‡½æ•°")
                print(f"  ä½¿ç”¨ --max-symbols 50 è®¾ç½®æ˜¾ç¤ºçš„ç¬¦å·æ•°é‡")
                print(f"  ä½¿ç”¨ -c ä½¿ç”¨ç´§å‡‘è¾“å‡ºæ¨¡å¼")
                print(f"  ä½¿ç”¨ --no-color ç¦ç”¨å½©è‰²è¾“å‡º")
                print(f"  ä½¿ç”¨ -v æ˜¾ç¤ºæ›´è¯¦ç»†çš„åˆ†æä¿¡æ¯")

if __name__ == "__main__":
    main()
